services:
  gallama:
    image: remichu/gallama:latest
    entrypoint:
      - gallama
      - run
      - -id
      - "model_name=whisper-large-v3-turbo"
#      - "model_name=whisper-large-v3"
      - -id
      - "model_name=qwen-2.5-VL-7B max_seq_len=32768"
#      - "model_name=qwen-2.5-VL-7B gpus=0,16,21,21 max_seq_len=32768"      # example on setting GPUs
      - -id
      - "model_name=kokoro"
    network_mode: host
    environment:
      - GALLAMA_HOME_PATH=/home/remichu/gallama         # change the path to where you store your model
    volumes:
      - /home/remichu/gallama:/home/remichu/gallama     # change the path to where you store your model
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]

  livekit-server:
    image: livekit/livekit-server:latest
    entrypoint:
     - "/livekit-server"
     - "--dev"
     - "--bind"
     - "0.0.0.0"
     - "--keys"
     - "devkey: secret"
    network_mode: host

  pai-agent:
    image: remichu/pai-agent:latest
    network_mode: host
#    volumes:
#      - /home/remichu/my_system_prompt.txt:/app/system_prompt.txt         # overwrite system prompt
#      - /home/remichu/my_tools.py:/app/tools.py                           # overwrite tool code


  token-service:
    image: remichu/pai-token:latest
    network_mode: host
